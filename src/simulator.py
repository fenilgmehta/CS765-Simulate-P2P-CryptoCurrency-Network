#!/usr/bin/env python3
import copy
import enum
import hashlib
import heapq
import json
import logging
import os
import random
from typing import List, Dict, Union, Tuple, Set

import coloredlogs
import numpy

g_logger = None


class SimulatorParameters:
    # Parameters in the configuration file (will be read from the file during initialization)
    def __init__(self) -> None:
        self.output_path: str = ''
        self.execution_time: float = 0.0

        # Point 1 of PDF: Total Nodes present in the P2P cryptocurrency network
        self.n_total_nodes: int = 0
        # Point 1 of PDF: z% of nodes are slow
        self.z_percent_slow_nodes: float = 0
        # Point 2 of PDF: Exponential Distribution Mean for the inter-arrival
        # time between transactions generated by a peer
        self.T_tx_exp_txn_interarrival_mean_sec: float = 0
        self.T_k_exp_sec_low: float = 0  # Point 7 of PDF: CPU power of the node is high
        self.T_k_exp_sec_high: float = 0  # Point 7 of PDF: CPU power of the node is low
        self.min_light_delay_sec: float = 0.0
        self.max_light_delay_sec: float = 0.0
        self.node_initial_coins_low: float = 0  # used to initialize the genesis block
        self.node_initial_coins_high: float = 0  # used to initialize the genesis block
        self.max_transactions_per_block: int = 0  # Point 7 of PDF: max transactions a block can store

        self.number_of_slow_nodes: int = 0
        self.number_of_fast_nodes: int = 0

    # Initialize the simulator parameters
    def load_from_file(self, config_file_name: str):
        global g_logger
        g_logger.debug(f"{config_file_name=}")

        # Open the config file and parse it
        config_file = open(config_file_name)
        parameters = json.load(config_file)

        # Read parameters from the config file
        self.output_path: str = os.path.abspath(parameters['output_path'])
        os.makedirs(self.output_path, exist_ok=True)
        self.execution_time: float = float(parameters['execution_time'])

        self.n_total_nodes: int = int(parameters['n_total_nodes'])
        self.z_percent_slow_nodes: float = float(parameters['z_percent_slow_nodes'])

        # Point 2 of PDF: Exponential Distribution Mean for the inter-arrival
        # time between transactions generated by a peer. Randomly generated
        self.T_tx_exp_txn_interarrival_mean_sec: float = float(parameters['T_tx_exp_txn_interarrival_mean_sec'])
        # Point 7 of PDF: Min and Max time to mine a block by a node
        # This is used to define mining power of each node in the network
        self.T_k_exp_sec_low: float = float(parameters['T_k_exp_sec_low'])
        self.T_k_exp_sec_high: float = float(parameters['T_k_exp_sec_high'])

        self.min_light_delay_sec: float = float(parameters['min_light_delay_sec'])
        self.max_light_delay_sec: float = float(parameters['max_light_delay_sec'])

        self.node_initial_coins_low: float = float(parameters['node_initial_coins_low'])
        self.node_initial_coins_high: float = float(parameters['node_initial_coins_high'])
        self.max_transactions_per_block: int = int(parameters['max_transactions_per_block'])

        # ---
        # z% nodes are slow
        self.number_of_slow_nodes: int = int(self.z_percent_slow_nodes * self.n_total_nodes) // 100
        if self.number_of_slow_nodes > self.n_total_nodes:
            g_logger.error('Condition not satisfied: 0 <= z_percent_slow_nodes <= 100')
            g_logger.warning('Making all nodes as slow because "z_percent_slow_nodes > 100"')
            self.number_of_slow_nodes = self.n_total_nodes

        # (100 - z)% nodes are fast
        self.number_of_fast_nodes: int = self.n_total_nodes - self.number_of_slow_nodes

    # Print all the Simulator Parameters to "stdout"
    def log_parameters(self):
        print()
        print(f'      n  = Number of peers specified in the config file : {self.n_total_nodes}')
        print(f'      z  = {self.z_percent_slow_nodes=} %')
        print(f'      z% = Number of slow nodes : {self.number_of_slow_nodes}')
        print(f'(100-z)% = Number of fast nodes : {self.number_of_fast_nodes}')
        print()
        print(f'    T_tx = (seconds) Exponential Distribution -> '
              f'Transaction Inter-arrival Mean = {self.T_tx_exp_txn_interarrival_mean_sec}')
        print(f' min t_k = (seconds) min block mining time = {self.T_k_exp_sec_low}')
        print(f' max t_k = (seconds) max block mining time = {self.T_k_exp_sec_high}')
        print(f' min ρij = (seconds) min light propagation delay = {self.min_light_delay_sec}')
        print(f' max ρij = (seconds) max light propagation delay = {self.max_light_delay_sec}')
        print()
        print(f'         min initial coins = {self.node_initial_coins_low}')
        print(f'         max initial coins = {self.node_initial_coins_high}')
        print(f'max transactions per block = {self.max_transactions_per_block}')
        print()


class Simulator:
    def __init__(self, sp: SimulatorParameters):
        self.simulator_parameters: SimulatorParameters = sp
        self.global_time: float = 0.0
        self.nodes_list: List[Node] = list()
        self.event_queue: EventQueue = EventQueue()
        pass

    def initialize(self):
        GENESIS_BLOCK = self.__create_genesis_block()
        list_slow_fast: List[bool] = ([False] * self.simulator_parameters.number_of_slow_nodes) \
                                     + ([True] * self.simulator_parameters.number_of_fast_nodes)
        # Create the nodes
        self.nodes_list = [Node(i, self, GENESIS_BLOCK, i_val) for i, i_val in enumerate(list_slow_fast)]
        # TODO: Implement point 4 of the problem statement
        #       i.e. Create a connected graph
        pass

    # REFER: https://www.geeksforgeeks.org/private-methods-in-python/
    def __create_genesis_block(self):
        """This method shall only be called during the start of the simulation"""

        # REFER: https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html#numpy.random.randint
        # “discrete uniform” distribution
        min_of_block_limit_and_nodes = min(self.simulator_parameters.n_total_nodes,
                                           self.simulator_parameters.max_transactions_per_block)
        # Uniform random distribution of money
        # In real life, these coins will be with people instead of nodes
        # TODO: change to numpy.random.uniform to generate float value for initial coins a node has
        money = numpy.random.randint(
            self.simulator_parameters.node_initial_coins_low,
            self.simulator_parameters.node_initial_coins_high,
            min_of_block_limit_and_nodes
        )
        # Uniform random distribution to nodes
        recv_node_idx = numpy.random.randint(
            0,
            self.simulator_parameters.n_total_nodes,
            min_of_block_limit_and_nodes
        )
        # Sender = -1 denotes that coins are created from thin air in the genesis block
        transactions = [Transaction(-1, -1, recv_idx, coins) for recv_idx, coins in zip(recv_node_idx, money)]
        return Block('-1', -1.0, 0, transactions, 0)

    def execute_next_event(self):
        """This will execute all events with event_completion_time==queue.top().event_completion_time"""
        global g_logger
        event: Event = self.event_queue.pop()
        if event == False:
            return False
        self.global_time = event.event_completion_time
        while True:
            if event.event_type == EventType.EVENT_TRANSACTION_CREATE:
                self.nodes_list[event.event_receiver_id].transaction_event_handler()
            elif event.event_type == EventType.EVENT_RECV_TRANSACTION:
                txn: Transaction = event.data_obj
                self.nodes_list[event.event_receiver_id].transaction_recv(txn, event.event_creator_id)
            elif event.event_type == EventType.EVENT_RECV_BLOCK:
                blk: Block = event.data_obj
                self.nodes_list[event.event_receiver_id].block_recv(blk, event.event_creator_id, self.global_time)
            elif event.event_type == EventType.EVENT_BLOCK_CREATE_SUCCESS:
                blk: Block = event.data_obj
                self.nodes_list[event.event_receiver_id].mining_complete(blk)
            else:
                g_logger.warning(f'Unexpected EventType={event.event_type} , {event=}')
            if self.event_queue.top() == False or self.event_queue.top().event_completion_time > self.global_time:
                break
            event = self.event_queue.pop()
        return True

    def get_global_time(self):
        return self.global_time

    def write_all_node_tree_to_file(self):
        for node in self.nodes_list:
            self.write_node_tree_to_file(
                node_obj=node,
                file_name=f'{self.simulator_parameters.output_path}/tree_{node.node_id}'
            )
        pass

    def write_node_tree_to_file(self, node_obj: 'Node', file_name: str):
        global g_logger
        temp_name = file_name
        i = 0
        while os.path.exists(temp_name):
            g_logger.error(f'File already exists: "{file_name}"')
            temp_name = file_name + f'_({str(i):03d}).txt'
            return
        with open(temp_name, 'w+') as f:
            f.write(node_obj.serialize_blockchain_to_str_v1())
        pass


class Transaction:
    def __init__(self, txn_time: float, id_sender: int, id_receiver: int, coin_amount: float):
        self.txn_time: float = txn_time
        self.id_sender: int = id_sender
        self.id_receiver: int = id_receiver
        self.coin_amount: float = coin_amount
        self.txn_hash: str = self.get_hash()

    def str(self) -> str:
        return str([self.txn_time, self.id_sender, self.id_receiver, self.coin_amount])

    def get_hash(self) -> str:
        return hashlib.md5(self.str().encode()).hexdigest()

    @staticmethod
    def size() -> int:
        """
        Returns size in Bytes
        NOTE: Size is assumed to be 1KB
        """
        return 1000


class Block:
    def __init__(self, prev_block_hash: str, creation_time: float, index: int, transactions: List[Transaction],
                 recv_time: float):
        """self.index is 0-indexed"""
        self.prev_block_hash: str = prev_block_hash
        self.creation_time: float = creation_time
        self.index: int = index
        self.transactions: List[Transaction] = transactions

        # This value/variable is NOT used during hash calculation of this block
        self.curr_block_hash: str = self.get_hash()
        self.recv_time: float = recv_time

    def update(self, prev_block_hash: str, creation_time: float, index: int, transactions: List[Transaction],
               recv_time: float):
        self.prev_block_hash = prev_block_hash
        self.creation_time = creation_time
        self.index = index
        self.transactions = transactions
        self.curr_block_hash = self.get_hash()
        self.recv_time = recv_time

    def get_hash(self) -> str:
        """
        Hash is calculated based on "self.prev_block_hash", "self.creation_time" and "self.transactions"
        """
        return hashlib.md5(self.str().encode()).hexdigest()

    def str(self) -> str:
        """
        NOTE: this does not include block hash
        String of "self.prev_block_hash", "self.creation_time", "self.index" and "self.transaction"
        """
        return str([self.prev_block_hash, self.creation_time, self.index, self.transactions])

    def serialize(self) -> str:
        return str([self.curr_block_hash, self.recv_time, self.prev_block_hash, self.creation_time, self.index,
                    self.transactions])

    def size(self) -> int:
        # REFER: https://stackoverflow.com/questions/14329794/get-size-in-bytes-needed-for-an-integer-in-python
        # In real life
        # return len(self.prev_block_hash) \
        #        + sys.getsizeof(self.creation_time) \
        #        + sys.getsizeof(self.index) \
        #        + (Transaction.size() * len(self.transactions))
        # In our simulator
        return Transaction.size() * len(self.transactions)


class Node:
    """Structure of a node on the P2P network"""

    def __init__(self, node_id: int, simulator: Simulator, GENESIS_BLOCK: Block, is_network_fast: bool):
        sp: SimulatorParameters = simulator.simulator_parameters
        self.node_id = node_id
        self.simulator: Simulator = simulator
        self.is_network_fast = is_network_fast
        # self.coins = 0  # current Balance of each node

        # Dictionary of connected peers
        self.neighbors: Dict[int, Node.NodeSiblingInfo] = dict()
        # The time at which a new block with chain lenght > local chain length is received
        self.last_receive_time: int = -1

        self.txn_all: Dict[str, Transaction] = dict()
        self.txn_pool: List[Transaction] = list()

        self.GENESIS_BLOCK = GENESIS_BLOCK
        self.blocks_all: Dict[str, Block] = {GENESIS_BLOCK.curr_block_hash: GENESIS_BLOCK}
        self.block_chain_leafs: List[str] = [GENESIS_BLOCK.curr_block_hash]  # NOTE: this is always sorted

        # Point 7 of PDF: Exponential Distribution Mean for the
        # block mining time by node. It is randomly generated
        # from Simulator Parameters "sp.T_k_exp_sec_low" and "sp.T_k_exp_sec_high"
        # Lower value  => High CPU power
        # Higher value => Low CPU power
        self.T_k_exp_block_mining_mean = numpy.random.uniform(sp.T_k_exp_sec_low, sp.T_k_exp_sec_high)

        # This is same for all nodes
        # Point 2 of PDF: Exponential Distribution Mean for inter-arrival time between transaction
        self.T_tx_exp_txn_interarrival_mean_sec = sp.T_tx_exp_txn_interarrival_mean_sec

        # This is same for all nodes
        # Max transactions a block can store
        self.max_transactions_per_block = sp.max_transactions_per_block

    def add_new_peer(self, new_peer_id: int, node_id: int, rho_ij: float, c_ij: int) -> None:
        """
        Adding new peer to the neighbors list
        Inserts an edge between this and new_peer in the node graph
        """
        self.neighbors[new_peer_id] = Node.NodeSiblingInfo(new_peer_id, rho_ij, c_ij)

    def remove_peer(self, peer_id: int) -> bool:
        if peer_id not in self.neighbors.keys():
            return False
        self.neighbors.pop(peer_id)
        return True

    # REFER: https://www.geeksforgeeks.org/inner-class-in-python/
    class NodeSiblingInfo:
        def __init__(self, node_id: int, rho_ij: float, c_ij: int):
            self.node_id: int = node_id

            # Network latency parameters
            # ρ_ij = positive minimum value corresponding to speed of light propagation delay
            self.rho_ij: float = rho_ij
            # link speed between i and j in bits per second
            self.c_ij: int = c_ij

        def find_message_latency(self, message_size_bits: int) -> float:
            # Point 5 of the PDF
            #   - dij is the queuing delay at senders side (i.e. node i)
            #   - dij is randomly chosen from an exponential distribution with some mean `96kbits/c_ij`
            #   - NOTE: d_ij must be randomly chosen for each message transmitted from "i" to "j"
            d_ij = numpy.random.exponential(96_000 / self.c_ij)  # TODO
            return self.rho_ij + (message_size_bits / self.c_ij) + d_ij

    def change_mining_branch(self, block_tail_hash_curr: str, block_tail_hash_new: str):
        # NOTE: this can be optimized by finding the common ancestor of the
        #       "current tail" on which mining is being done and the "new tail"
        txn_pool_temp: Set[Transaction] = set(self.txn_all.values())
        curr_block_hash: str = self.block_chain_leafs[-1]
        while curr_block_hash != self.GENESIS_BLOCK.curr_block_hash:
            for txn in self.blocks_all[curr_block_hash].transactions:
                txn_pool_temp.remove(txn)
            curr_block_hash = self.blocks_all[curr_block_hash].prev_block_hash
        self.txn_pool = list(txn_pool_temp)

    def is_transaction_validate(self, transaction_obj):
        global g_logger
        senders_balance = 0.0
        curr_blockchain_hash = self.block_chain_leafs[-1]
        while curr_blockchain_hash != self.GENESIS_BLOCK.prev_block_hash:
            for txn in self.blocks_all[curr_blockchain_hash].transactions:
                if transaction_obj.txn_hash == txn.txn_hash:
                    # Transaction is already included in the past block
                    return False
                if transaction_obj.id_sender == txn.id_sender:
                    senders_balance -= txn.coin_amount
                elif transaction_obj.id_sender == txn.id_receiver:
                    senders_balance += txn.coin_amount
                if senders_balance < 0.0:
                    g_logger.error(f'The blockchain has -ve balance for {transaction_obj.id_sender=}')
                    g_logger.error(f'Blockchain tail = {self.block_chain_leafs[-1]}')
                    # TODO: do more verbose logging
            curr_blockchain_hash = self.blocks_all[curr_blockchain_hash].prev_block_hash
        return senders_balance >= transaction_obj.coin_amount

    def transaction_create(self):
        next_txn_gen_event_delay = numpy.exp(
            1 / self.simulator.simulator_parameters.T_tx_exp_txn_interarrival_mean_sec
        )  # TODO: time unit is seconds
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + next_txn_gen_event_delay,
                EventType.EVENT_TRANSACTION_CREATE,
                self.node_id,
                self.node_id,
                None
            )
        )

    def transaction_event_handler(self):
        """
        - Randomly Select a node for receiver
        - Coin Amount : generate randomly
        """
        txn_receiver: Node = random.choice([node for node in self.simulator.nodes_list if node.node_id != self.node_id])
        txn_amount: float = round(random.uniform(0, 50), 2)  # TODO : make this range better
        txn_obj: Transaction = Transaction(self.simulator.get_global_time(), self.node_id, txn_receiver.node_id, txn_amount)

        if self.is_transaction_validate(txn_obj):
            self.txn_pool.append(txn_obj)
            self.txn_all[txn_obj.txn_hash] = txn_obj
        # NOTE: even invalid transactions are send to neighbors to prove that other
        #       peers are working properly they will discard invalid received data
        for node in self.neighbors.values():
            self.transaction_send(txn_obj, node)

        self.transaction_create()

    def transaction_send(self, transaction_obj: Transaction, receiver_node: NodeSiblingInfo):
        """
            Receiver Obj : Peer Node of type NodeSiblingInfo
            it computes the latency to send the transaction
            it then generates an event in the event queue at that time.
        """
        network_delay: float = receiver_node.find_message_latency(8 * transaction_obj.size())
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + network_delay,
                EventType.EVENT_RECV_TRANSACTION,
                self.node_id,
                receiver_node.node_id,
                transaction_obj
            )
        )

    def transaction_recv(self, transaction_obj: Transaction, senders_id: int):
        # IF I have already received the transaction; THEN I drop it
        if transaction_obj.txn_hash in self.txn_all:
            return
        # IF transaction is invalid; then I drop it
        if self.is_transaction_validate(transaction_obj) == False:
            return
        # Store the block and forward it to others
        self.txn_all[transaction_obj.txn_hash] = transaction_obj
        for node in self.neighbors.values():
            # Do NOT send the transaction back to the node from which it was received
            if node.node_id == senders_id:
                continue
            self.transaction_send(transaction_obj, node)
        pass

    def is_block_validate(self, block_obj: Block):
        """NOTE: first transaction of all blocks SHOULD ONLY be mining reward transaction"""
        global g_logger
        if len(block_obj.transactions) <= 1:
            return False
        if block_obj.prev_block_hash not in self.blocks_all:
            g_logger.warning(f'Block received whose parent is not yet received to this Node')
            g_logger.warning(f'{self.node_id=} , {block_obj=}')
        if self.blocks_all[block_obj.prev_block_hash].index + 1 != block_obj.index:
            return False
        for txn in block_obj.transactions[1:]:
            if self.is_transaction_validate(txn):
                continue
            return False
        return True

    def block_send(self, block_obj: Block, receivers_id: int):
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + numpy.random.exponential(1),  # TODO
                EventType.EVENT_RECV_BLOCK,
                self.node_id,
                receivers_id,
                block_obj
            )
        )

    def block_recv(self, block_obj: Block, senders_id: int, current_time: float):
        global g_logger
        # set the block receive time
        block_obj.recv_time = current_time

        # IF I have already received the block; THEN I drop it
        if block_obj.curr_block_hash in self.blocks_all:
            return
        # IF block_obj.index < max value of current blockchain length; THEN I drop it
        if block_obj.index < self.blocks_all[self.block_chain_leafs[-1]].index:
            return
        # IF block is invalid; then I drop it
        if self.is_block_validate(block_obj) == False:
            return
        # Store the block and forward it to others
        self.blocks_all[block_obj.curr_block_hash] = block_obj
        if block_obj.prev_block_hash not in self.blocks_all.keys():
            g_logger.warning(
                f'Block received whose parent is not received. {self.node_id=} , {senders_id=} , {block_obj=}')
        for node in self.neighbors.values():
            # Do NOT send the block back to the node from which it was received
            if node.node_id == senders_id:
                continue
            self.block_send(block_obj, node.node_id)

        to_start_new_mining = False
        if block_obj.index > self.blocks_all[self.block_chain_leafs[-1]].index:
            to_start_new_mining = True
            self.last_receive_time = current_time
            self.change_mining_branch(self.block_chain_leafs[-1], block_obj.curr_block_hash)

        # Insert the block_obj into self.block_chain_leafs
        idx_insert = 0
        for i in range(len(self.block_chain_leafs) - 1, -1, -1):  # "i" goes from "N-1" to "0"
            # NOTE: Mostly, the less than condition will never be true in our simulation
            #       However, it can be true in real life
            if block_obj.index <= self.blocks_all[self.block_chain_leafs[i]].index:
                continue
            idx_insert = i + 1
            break
        self.block_chain_leafs.insert(idx_insert, block_obj)
        if to_start_new_mining:
            self.mining_start()
        pass

    def get_new_transaction_greedy(self) -> List[Transaction]:
        if len(self.txn_pool) <= self.max_transactions_per_block - 1:
            return copy.deepcopy(self.txn_pool)
        return copy.deepcopy(self.txn_pool[:self.max_transactions_per_block - 1])

    def get_new_block(self) -> Block:
        # Point 7 of the PDF
        mining_completion_time = self.simulator.get_global_time() + numpy.random.exponential(1)  # TODO
        return Block(
            self.block_chain_leafs[-1],
            mining_completion_time,
            self.blocks_all[self.block_chain_leafs[-1]].index + 1,
            self.get_new_transaction_greedy(),
            mining_completion_time
        )
        pass

    def mining_start(self):
        new_block: Block = self.get_new_block()
        if len(new_block.transactions) == 0:
            return False
        self.simulator.event_queue.push(
            Event(
                new_block.creation_time,
                EventType.EVENT_BLOCK_CREATE_SUCCESS,
                self.node_id,
                self.node_id,
                new_block
            )
        )
        return True

    def mining_complete(self, block: Block):
        global g_logger
        # A "Block" which created new longest blockchain was received after the
        # mining started. Hence, we discard this mining complete request because
        # in real life this mining work is to be discarded.
        if block.creation_time < self.last_receive_time:
            return
        if self.blocks_all[self.block_chain_leafs[-1]].index > block.index:
            g_logger.warning(
                f'Block mining complete but a chain with longer length is present in "self.block_chain_leafs"'
            )
            g_logger.warning(f'len queue = {self.blocks_all[self.block_chain_leafs[-1]].index=}')
            g_logger.warning(f'len mined = {self.blocks_all[block.curr_block_hash].index=}')
        if self.block_chain_leafs[-1] != block.prev_block_hash:
            g_logger.warning(f'len queue = {self.blocks_all[self.block_chain_leafs[-1]].index=}')
            g_logger.warning(f'len mined = {self.blocks_all[block.curr_block_hash].index=}')

        # Add block to the blockchain
        self.blocks_all[block.curr_block_hash] = block
        self.block_chain_leafs[-1] = block.curr_block_hash

        # Broadcast the "block" to all "self.neighbors"
        for node in self.neighbors.values():
            self.block_send(block, node.node_id)
        pass

    def serialize_blockchain_to_str_v1(self) -> str:
        # TODO: update this if required
        return '\n'.join([block.serialize() for block in self.blocks_all.values()])


# REFER: https://www.tutorialspoint.com/enum-in-python
class EventType(enum.Enum):
    EVENT_UNDEFINED = 0
    EVENT_TRANSACTION_CREATE = 1  # Queue -> data_obj = None
    EVENT_SEND_TRANSACTION = 2
    EVENT_RECV_TRANSACTION = 3  # Queue -> transaction_obj: Transaction
    EVENT_SEND_BLOCK = 4
    EVENT_RECV_BLOCK = 5  # Queue -> block_obj: Block
    EVENT_BLOCK_CREATE = 6
    EVENT_BLOCK_CREATE_SUCCESS = 7  # Queue -> data_obj: Block


class Event:
    def __init__(
            self,
            event_completion_time: float,
            event_type: EventType,
            event_creator_id: int,
            event_receiver_id: int,
            data_obj: Union[None, Transaction, Block]
    ):
        self.event_completion_time: float = event_completion_time
        self.event_type: EventType = event_type
        self.event_creator_id: int = event_creator_id
        self.event_receiver_id: int = event_receiver_id
        self.data_obj = data_obj


# REFER: https://docs.python.org/3/library/heapq.html
# REFER: https://www.geeksforgeeks.org/heap-queue-or-heapq-in-python/
class EventQueue:
    def __init__(self):
        self.events: List[Tuple[float, Event]] = list()

    def push(self, new_event: Event):
        heapq.heappush(self.events, (new_event.event_completion_time, new_event))

    def pop(self) -> Event:
        return heapq.heappop(self.events)[1]

    def top(self) -> Union[Event, bool]:
        if len(self.events) == 0:
            return False
        return self.events[0][1]


def Main(args: Dict):
    global g_logger
    sp = SimulatorParameters()
    sp.load_from_file(args['config'])
    sp.log_parameters()
    mySimulator = Simulator(sp)
    mySimulator.initialize()
    while mySimulator.get_global_time() < sp.execution_time:
        status = mySimulator.execute_next_event()
        if status == False:
            g_logger.info('No events present in the event queue. Exiting...')
            break
    mySimulator.write_all_node_tree_to_file()


if __name__ == '__main__':
    import argparse

    my_parser = argparse.ArgumentParser(prog='simulator.py',
                                        description='Discrete Event Simulator for a P2P Cryptocurrency Network',
                                        epilog='Enjoy the program :)',
                                        prefix_chars='-',
                                        allow_abbrev=False,
                                        add_help=True)
    my_parser.version = '1.0'
    my_parser.add_argument('--version', action='version')
    my_parser.add_argument('-D',
                           '--debug',
                           action='store_true',
                           help='Print debug information')
    my_parser.add_argument('-c',
                           '--config',
                           action='store',
                           type=str,
                           help='Path to the config file',
                           required=True)

    # Execute the parse_args() method
    args: argparse.Namespace = my_parser.parse_args()

    # Initialize "g_logger"
    g_logger = logging.getLogger(__name__)
    # REFER: https://stackoverflow.com/questions/384076/how-can-i-color-python-logging-output
    #            - https://github.com/xolox/python-coloredlogs
    if args.debug:
        # g_logger.setLevel(logging.DEBUG)
        coloredlogs.install(fmt='%(levelname)-8s :: [%(lineno)4s] %(name)10s :: %(message)s', level='DEBUG',
                            logger=g_logger)
    else:
        # g_logger.setLevel(logging.INFO)
        coloredlogs.install(fmt='%(levelname)-8s :: [%(lineno)4s] %(name)10s :: %(message)s', level='INFO',
                            logger=g_logger)

    g_logger.debug('Debugging is ON')
    g_logger.debug(f'{args=}')
    g_logger.handlers[
        0].flush()  # REFER: https://stackoverflow.com/questions/13176173/python-how-to-flush-the-log-django/13753911

    Main(vars(args))
